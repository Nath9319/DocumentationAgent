{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e990f15",
   "metadata": {},
   "source": [
    "### Capture Docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9dd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENTATION_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert technical writer tasked with producing **clear, complete,\n",
    "developer-ready Markdown documentation** for the Python symbol `{name}`.\n",
    "\n",
    "Node details\n",
    "------------\n",
    "• File Path: {path}  \n",
    "• Raw Docstring:  \n",
    "\\\"\\\"\\\"{docstring}\\\"\\\"\\\"\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "Write a Markdown block that includes **all** of the sections below (omit the\n",
    "word “None” if a section truly has no content).  \n",
    "Do **not** quote or reproduce the source code itself.\n",
    "\n",
    "Sections to generate\n",
    "1. **Function/Class Name and Signature** – infer the full signature if it is\n",
    "   not spelled out in the docstring.\n",
    "2. **Description** – high-level overview of behaviour and intent.\n",
    "3. **Parameters / Attributes** – table with *name, type, description*.\n",
    "4. **Expected Input** – data types, constraints, edge cases.\n",
    "5. **Returns** – type and meaning of the return value.\n",
    "6. **Detailed Logic** – step-by-step explanation of algorithms and any\n",
    "   interactions with other components.\n",
    "7. *(Optional)* **Raises / Errors** – exceptions or error conditions.\n",
    "8. *(Optional)* **Usage Example** – a concise runnable snippet.\n",
    "\n",
    "Formatting rules\n",
    "• Use Markdown headers (`###`) for the top-level title and bold section names.  \n",
    "• Keep line length ≤ 120 characters.  \n",
    "• Do **not** invent behaviour not implied by the docstring.  \n",
    "• Do **not** add conceptual-graph or dependency content.\n",
    "\n",
    "Example layout\n",
    "--------------\n",
    "### calculate_payment(principal: float, annual_rate: float, num_payments: int) -> float\n",
    "\n",
    "**Description:**  \n",
    "Calculates the fixed periodic payment required to fully amortize a loan using the net present-value formula.\n",
    "\n",
    "**Parameters:**  \n",
    "| Name | Type  | Description                           |\n",
    "|------|-------|---------------------------------------|\n",
    "| principal | float | Initial loan amount              |\n",
    "| annual_rate | float | Annual interest rate (e.g., 0.05) |\n",
    "| num_payments | int | Total number of payments         |\n",
    "\n",
    "**Expected Input:**  \n",
    "• `principal` > 0  \n",
    "• `annual_rate` ≥ 0  \n",
    "• `num_payments` > 0\n",
    "\n",
    "**Returns:**  \n",
    "`float` – payment amount per period.\n",
    "\n",
    "**Detailed Logic:**  \n",
    "• Zero-interest shortcut divides `principal` evenly.  \n",
    "• Otherwise computes periodic rate and applies amortisation formula.\n",
    "\n",
    "Begin the Markdown documentation now.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558a0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from typing import Dict, Union\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4acb49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────  LLM chain  ────────────────────────────\n",
    "load_dotenv()                                     # pulls key / deployment name\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(DOCUMENTATION_PROMPT_TEMPLATE)\n",
    "chain  = prompt | llm | StrOutputParser()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526271b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_file(py_path: Path) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse *one* Python file and return\n",
    "    {symbol_name: {'path', 'docstring', 'Documentation'}}.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src  = py_path.read_text(encoding=\"utf-8\")\n",
    "        tree = ast.parse(src, filename=str(py_path))\n",
    "    except (OSError, SyntaxError, UnicodeDecodeError):\n",
    "        return {}                                  # skip unreadable / bad files\n",
    "\n",
    "    out: Dict[str, Dict[str, str]] = {}\n",
    "    for node in tree.body:                         # top-level defs only\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "            doc = ast.get_docstring(node) or \"\"\n",
    "            payload = {\n",
    "                \"name\": node.name,\n",
    "                \"path\": str(py_path),\n",
    "                \"docstring\": doc,\n",
    "            }\n",
    "            out[node.name] = {\n",
    "                \"path\": str(py_path),\n",
    "                \"docstring\": doc,\n",
    "                \"Documentation\": chain.invoke(payload),\n",
    "            }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b035e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_docstrings(\n",
    "    root: Union[str, Path],\n",
    "    *,\n",
    "    workers: int | None = None\n",
    ") -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively scan *root* for *.py files and return\n",
    "\n",
    "        { symbol_name :\n",
    "            { 'path': str,\n",
    "              'docstring': str,\n",
    "              'Documentation': str } }\n",
    "\n",
    "    Documentation is generated by the LLM chain.\n",
    "    \"\"\"\n",
    "    root     = Path(root).expanduser().resolve()\n",
    "    workers  = workers or os.cpu_count()\n",
    "    result: Dict[str, Dict[str, str]] = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as pool:\n",
    "        futures = {pool.submit(_process_file, p): p\n",
    "                   for p in root.rglob(\"*.py\")}\n",
    "        for fut in as_completed(futures):\n",
    "            result.update(fut.result())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b429fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = collect_docstrings(\"CalculatorCode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04433aa6",
   "metadata": {},
   "source": [
    "### Document Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ceb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def save_docs_to_files(docs: dict, output_root: str) -> None:\n",
    "    \"\"\"\n",
    "    Save each LLM-generated Markdown string to\n",
    "    output\\\\<project structure>\\\\<py-file-stem>\\\\<symbol>.md.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    Source path:  CalculatorCode\\\\app\\\\core\\\\config.py\n",
    "    Output file:  output\\\\CalculatorCode\\\\app\\\\core\\\\config\\\\<symbol>.md\n",
    "    \"\"\"\n",
    "    output_root = Path(output_root).resolve()\n",
    "\n",
    "    for symbol, meta in docs.items():\n",
    "        src_path = Path(meta[\"path\"].replace(\"\\\\\", \"/\")).resolve()          # normalise[1]\n",
    "\n",
    "        # locate the project root folder (e.g. \"CalculatorCode\")\n",
    "        try:\n",
    "            start_idx = next(i for i, p in enumerate(src_path.parts)\n",
    "                             if p.lower() == \"calculatorcode\")\n",
    "        except StopIteration:                                              # fallback: full path\n",
    "            start_idx = 0\n",
    "\n",
    "        # path up to the .py file’s parent\n",
    "        rel_parent = Path(*src_path.parts[start_idx:-1])\n",
    "\n",
    "        # final directory: …/<py-file-stem>/\n",
    "        target_dir = output_root / rel_parent / src_path.stem\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # write the Markdown\n",
    "        (target_dir / f\"{symbol}.md\").write_text(\n",
    "            meta[\"Documentation\"], encoding=\"utf-8\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68852ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_docs_to_files(docs, output_root= \"docstring_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfcb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
